# modulos/B_resultados.py

# modulos/B_resultados.py

import pandas as pd
import numpy as np
import networkx as nx
import geopandas as gpd
from typing import List, Dict, Tuple, Optional

from modulos.B_algoritmos import _filter_subgraph, _get_case_count, _create_graph_from_data, expansion_tree, floyd_warshall_routes, kruskal_mst_analysis

# --- Subtipos de Delito Focales para el Reporte Estrat√©gico ---
CRIME_FOCUS_TYPES = ['EXTORSI√ìN', 'HOMICIDIOS', 'SICARIATO'] 


def _preparar_datos_filtrados(df_delitos: pd.DataFrame, gdf_geo: gpd.GeoDataFrame, department: str) -> Tuple[pd.DataFrame, gpd.GeoDataFrame]:
    """
    Realiza el filtrado y normalizaci√≥n de DataFrames para asegurar la coincidencia de nombres
    antes de pasarlos a la funci√≥n _create_graph_from_data.
    
    Esta funci√≥n SOLUCIONA el problema de los 'ceros' al estandarizar los nombres de distritos.
    """
    # Normalizaci√≥n del departamento
    dept_norm = department.upper().strip()

    # 1. Filtrar GeoDataFrame por el departamento
    # Suponemos que la columna de departamento en el GDF es 'NOMBDEP'
    gdf_dep = gdf_geo[gdf_geo["NOMBDEP"].str.upper().str.strip() == dept_norm].copy()
    
    if gdf_dep.empty:
        print(f"Error: No se encontraron datos geogr√°ficos para {department}.")
        return pd.DataFrame(), gpd.GeoDataFrame()

    # ** PASO CR√çTICO: NORMALIZACI√ìN DE GEOMETR√çA **
    gdf_dep = gdf_dep[gdf_dep.geometry.notna()].copy()

    # 2. Filtrar el DataFrame de Delitos
    # Suponemos que la columna de departamento en el DF es 'DPTO_HECHO_NEW'
    df_dep = df_delitos[df_delitos["DPTO_HECHO_NEW"].str.upper().str.strip() == dept_norm].copy()
    
    if df_dep.empty:
        print(f"Advertencia: El DataFrame de delitos filtrado por departamento est√° vac√≠o para {department}.")
        return pd.DataFrame(), gdf_dep
    
    
    # Crea un set de nombres de distritos v√°lidos del GDF
    valid_districts = set(gdf_dep["NOMBDIST"].str.upper().str.strip())
    
    # Normaliza la columna 'DIST_HECHO' en el DF de delitos
    df_dep['DIST_HECHO_NORM'] = df_dep['DIST_HECHO'].str.upper().str.strip()
    
    # Filtra el DF de delitos para solo incluir distritos que existen en el GDF
    df_dep = df_dep[df_dep['DIST_HECHO_NORM'].isin(valid_districts)].copy()
    
    print(f"[INFO] Preparaci√≥n de datos: {len(df_dep)} casos de delitos y {len(gdf_dep)} distritos listos.")
    
    return df_dep, gdf_dep


# === 1. FUNCI√ìN DE C√ÅLCULO Y CONSOLIDACI√ìN: consolidar_resultados ===


def consolidar_resultados(G_base: nx.Graph, department: str, epicentro: str) -> Dict:
    """
    Ejecuta todos los an√°lisis de grafos y consolida los hallazgos.
    """
    print(f"\n==================== 1/3. INICIANDO CONSOLIDACI√ìN DE RESULTADOS PARA {department.upper()} ====================")

    # 1. Filtro y Verificaci√≥n (G_base ya debe ser el grafo del departamento)
    G_filtered = G_base # Asumimos que _create_graph_from_data ya cre√≥ el grafo filtrado
    
    if G_filtered.number_of_nodes() == 0:
        print("Advertencia: El grafo est√° vac√≠o. No se puede generar el reporte.")
        return {}

    # 2. Ejecuci√≥n de los Algoritmos de Grafo
    print("[INFO] Ejecutando algoritmos de an√°lisis estructural...")
    # NOTA: Los algoritmos deben poder manejar grafos grandes y filtrar internamente
    bfs_stats = expansion_tree(G_base, epicentro, method='bfs', crime_types=CRIME_FOCUS_TYPES, department=department)
    fw_stats = floyd_warshall_routes(G_base, mode='volume', crime_types=CRIME_FOCUS_TYPES, department=department)
    kruskal_stats = kruskal_mst_analysis(G_base, k=None, crime_types=CRIME_FOCUS_TYPES, department=department)
    
    reporte_final = {}
    
    # --- PARTE 1: M√©tricas de Alto Nivel üìä ---
    # ... (Se mantiene la l√≥gica original, usando G_filtered = G_base) ...
    total_casos_focus_subgraph = sum(_get_case_count(G_filtered, n, CRIME_FOCUS_TYPES) for n in G_filtered.nodes())
    total_nodos_subgraph = G_filtered.number_of_nodes()
    
    try:
        all_paths = [p['path'] for p in fw_stats.get('critical_paths', [])]
        node_counts = pd.Series([node for path in all_paths for node in path]).value_counts()
        bridge_threshold = node_counts.quantile(0.75) if not node_counts.empty else 0
        num_distritos_puente = len(node_counts[node_counts >= bridge_threshold])
        bridge_nodes_list = list(node_counts[node_counts >= bridge_threshold].index)
    except:
        num_distritos_puente = 0
        bridge_nodes_list = []

    metrica_global = {
        'total_distritos_analizados': total_nodos_subgraph,
        'total_casos_focus_subtipos': total_casos_focus_subgraph,
        'total_epicentro_detectados': 1, 
        'total_rutas_criticas_fw': fw_stats.get('num_caminos_calculados', 0),
        'total_distritos_puente': num_distritos_puente,
        'total_conexiones_mst': kruskal_stats.get('MST_aristas', 0),
        'total_casos_ruta_max_conc': fw_stats.get('mayor_concentracion_casos', 0),
        'peso_total_mst_inverso': kruskal_stats.get('peso_total_MST', 0),
    }
    reporte_final['M√©tricas Globales'] = metrica_global
    
    # --- PARTE 2: Nodos Estrat√©gicos Identificados (Distritos) üö® ---
    print("\n--- 2. IDENTIFICANDO NODOS ESTRAT√âGICOS ---")
    
    # ... (Se mantiene la l√≥gica original de clasificaci√≥n y reporte) ...
    nodos_reporte = []
    cases_list = [_get_case_count(G_filtered, n, CRIME_FOCUS_TYPES) for n in G_filtered.nodes()]
    threshold_alta = np.percentile(cases_list, 75) if cases_list else 0
    
    for node in G_filtered.nodes():
        cases_total_focus = _get_case_count(G_filtered, node, CRIME_FOCUS_TYPES)
        cases_by_type = G_filtered.nodes[node].get('cases_by_type', {})
        extorsion_count = cases_by_type.get('EXTORSI√ìN', 0)
        homicidio_sicariato_count = cases_by_type.get('HOMICIDIOS', 0) + cases_by_type.get('SICARIATO', 0) 

        recomendacion = ""
        is_epicentro = (node == epicentro)
        is_bridge = node in bridge_nodes_list

        if cases_total_focus > threshold_alta and (extorsion_count > 0 or homicidio_sicariato_count > 0):
            recomendacion += "Requiere **Intervenci√≥n Inmediata (Foco Rojo)**. "
        elif is_bridge and G_filtered.degree(node) >= 3:
            recomendacion += "Es un **Distrito Puente Estrat√©gico**, su control afecta a m√∫ltiples zonas. "
        elif is_epicentro:
            recomendacion += "**Epicentro/Origen** de la expansi√≥n delictiva. "
        elif cases_total_focus > np.percentile(cases_list, 50):
            recomendacion += "Zona de **Riesgo Alto**, concentraci√≥n significativa de los subtipos focales. "
        else:
            recomendacion += "Zona de Riesgo Moderado. "
            
        nodos_reporte.append({
            'Distrito': node,
            'Casos (Focus)': cases_total_focus,
            'Extorsi√≥n': extorsion_count,
            'Homicidio/Sicariato': homicidio_sicariato_count,
            'Grado': G_filtered.degree(node),
            'Recomendaci√≥n Estrat√©gica': recomendacion.strip()
        })
        
    df_nodos_reporte = pd.DataFrame(nodos_reporte).sort_values(by='Casos (Focus)', ascending=False)
    reporte_final['Nodos Estrat√©gicos'] = df_nodos_reporte.to_dict('records')


    # --- PARTE 3: Rutas Cr√≠ticas de Propagaci√≥n (Floyd‚ÄìWarshall) üó∫Ô∏è ---
    print("\n--- 3. IDENTIFICANDO RUTAS CR√çTICAS ---")

    # ... (Se mantiene la l√≥gica original) ...
    critical_paths = fw_stats.get('critical_paths', [])
    rutas_reporte = []
    max_concentration = metrica_global['total_casos_ruta_max_conc']
    
    for i, ruta in enumerate(critical_paths[:10]): 
        if max_concentration > 0:
            pct = ruta['concentration'] / max_concentration
            riesgo = "CR√çTICO (M√°xima Concentraci√≥n)" if pct >= 0.9 else ("ALTO" if pct >= 0.7 else ("MEDIO" if pct >= 0.5 else "BAJO"))
        else:
            riesgo = "BAJO (Concentraci√≥n Nula)"

        rutas_reporte.append({
            'Ruta ID': i + 1,
            'Casos Acumulados (Focus)': ruta['concentration'],
            'Distritos (Corredor)': " -> ".join(ruta['path']),
            'Riesgo': riesgo,
            'Peso Distancia (Inverso)': f"{ruta['cost']:.4f}",
        })

    reporte_final['Rutas Cr√≠ticas FW'] = rutas_reporte

    # --- PARTE 4: Red M√≠nima de Intervenci√≥n (Kruskal MST) üîó ---
    print("\n--- 4. ANALIZANDO RED M√çNIMA DE INTERVENCI√ìN ---")
    
    # ... (Se mantiene la l√≥gica original) ...
    mst_metrica = {
        'MST_nodos': kruskal_stats.get('MST_nodos', 0),
        'MST_aristas': kruskal_stats.get('MST_aristas', 0),
        'aristas_eliminadas': kruskal_stats.get('aristas_eliminadas', 0),
        'peso_total_MST_inverso': f"{kruskal_stats.get('peso_total_MST', 0):.4f}",
        'reduccion_complejidad_pct': kruskal_stats.get('reduccion_peso_pct', 0),
        'cobertura_territorial': kruskal_stats.get('cobertura_territorial', "0.00%"),
        'eficiencia_complejidad': f"Se mantiene el {kruskal_stats.get('cobertura_territorial', '0.00%')} del territorio con una reducci√≥n de {kruskal_stats.get('reduccion_peso_pct', 0):.2f}% en la complejidad de la red."
    }
    reporte_final['M√©tricas MST'] = mst_metrica
    
    central_column_rank = kruskal_stats.get('central_column_rank', []) 
    conexiones_reporte = []
    
    for u, v, cost in central_column_rank:
        cases_u = _get_case_count(G_filtered, u, CRIME_FOCUS_TYPES)
        cases_v = _get_case_count(G_filtered, v, CRIME_FOCUS_TYPES)
        
        conexiones_reporte.append({
            'Conexi√≥n (Distritos)': f"{u} <-> {v}",
            'Casos Acumulados (Focus)': cases_u + cases_v,
            'Costo (Peso Inverso)': f"{cost:.4f}",
            'Recomendaci√≥n': "Enlace de M√≠nima Conexi√≥n, crucial para la intervenci√≥n centralizada."
        })
        
    reporte_final['Conexiones Cr√≠ticas MST'] = conexiones_reporte

    print("\n==================== 2/3. CONSOLIDACI√ìN COMPLETADA ====================")
    return reporte_final


# === 2. FUNCI√ìN DE IMPRESI√ìN: imprimir_reporte_final (Sin cambios) ===

def imprimir_reporte_final(reporte: Dict):
    """Formatea e imprime el reporte consolidado en la consola (solo texto)."""
    
    if not reporte or 'M√©tricas Globales' not in reporte:
        print("\nEl reporte est√° vac√≠o o incompleto. No se puede imprimir.")
        return
        
    print("\n\n" + "="*80)
    print("                 üèÜ INFORME ESTRAT√âGICO CONSOLIDADO DE DELITOS üèÜ")
    print(f" (Foco: {', '.join(CRIME_FOCUS_TYPES)})")
    print("="*80)

    # --- PARTE 1: M√©tricas de Alto Nivel ---
    print("\n## 1. M√©tricas Clave de Vulnerabilidad Territorial üìà")
    print("---")
    mg = reporte['M√©tricas Globales']
    
    print(f"Total Distritos Analizados:** {mg['total_distritos_analizados']}")
    print(f"Casos Focales Totales (Focus Subtipos):** {mg['total_casos_focus_subtipos']}")
    print(f"Total Epicentros Detectados:** {mg['total_epicentro_detectados']}")
    print(f"Total Rutas Cr√≠ticas FW:** {mg['total_rutas_criticas_fw']}")
    print(f"Total Distritos Puente (Estrat√©gicos):** {mg['total_distritos_puente']}")
    print(f"Total Conexiones Esenciales MST:** {mg['total_conexiones_mst']}")
    print(f"Casos en Ruta M√°x. Concentraci√≥n:** {mg['total_casos_ruta_max_conc']}")
    
    # --- PARTE 2: Nodos Estrat√©gicos Identificados ---
    print("\n## 2. Nodos Estrat√©gicos (Distritos) y Riesgo Espec√≠fico üö®")
    print("---")
    
    df_nodos = pd.DataFrame(reporte['Nodos Estrat√©gicos'])
    
    print(df_nodos[['Distrito', 'Casos (Focus)', 'Extorsi√≥n', 'Homicidio/Sicariato', 'Grado', 'Recomendaci√≥n Estrat√©gica']].to_markdown(index=False, floatfmt=".0f"))
    print("\n**Nota:** Casos (Focus) = Suma de Extorsi√≥n, Homicidio y Sicariato.")
    
    print("\n## 3. Corredores Delictivos (Rutas Cr√≠ticas FW) üó∫Ô∏è")
    print("---")

    # 1. Crea el DataFrame. (Aseg√∫rate de que esta l√≠nea y las siguientes est√°n INDENTADAS)
    df_rutas = pd.DataFrame(reporte['Rutas Cr√≠ticas FW']) 

    # 2. Bloque try-except para manejar el error de columna.
    try:
        # ... (Todo el c√≥digo de impresi√≥n de rutas DEBE ESTAR INDENTADO aqu√≠) ...
        if df_rutas.empty:
            print("No se generaron rutas cr√≠ticas de Floyd-Warshall.")
        else:
            print("**Top Rutas con Mayor Concentraci√≥n de Casos Focales**")
            
            # Esta l√≠nea DEBE ESTAR INDENTADA.
            rutas_criticas_altas = df_rutas[df_rutas['Riesgo'].isin(['CR√çTICO (M√°xima Concentraci√≥n)', 'ALTO'])]
            
            if not rutas_criticas_altas.empty:
                print(rutas_criticas_altas.to_markdown(index=False))
            else:
                print("No se identificaron rutas CR√çTICAS o ALTAS con la concentraci√≥n actual de casos.")

    except KeyError:
        print("No se generaron rutas cr√≠ticas de Floyd-Warshall o el c√°lculo de Riesgo fall√≥.")

    # --- PARTE 4: Red M√≠nima de Intervenci√≥n (MST) ---
    print("\n## 4. Red M√≠nima Esencial de Intervenci√≥n (Kruskal MST) üîó")
    print("---")
    
    mm = reporte['M√©tricas MST']
    print(f"* **Cobertura Territorial:** {mm['cobertura_territorial']}")
    print(f"* **Eficiencia y Complejidad Reducida:** {mm['eficiencia_complejidad']}")
    print(f"* **Aristas No Esenciales Eliminadas (Complejidad Reducida):** {mm['aristas_eliminadas']}")
    print(f"* **Peso Total Inverso del MST (Costo):** {mm['peso_total_MST_inverso']}")
    
    print("\n### Conexiones Cr√≠ticas del MST (Enlaces m√°s esenciales y de mayor riesgo)")
    df_conexiones = pd.DataFrame(reporte['Conexiones Cr√≠ticas MST'])
    print(df_conexiones.to_markdown(index=False, floatfmt=".4f"))
    
    print("\n" + "="*80)
    print("FIN DEL INFORME ESTRAT√âGICO")
    print("="*80)

# === 3. FUNCI√ìN PRINCIPAL: mostrar_resultados (Nueva L√≥gica de Filtrado) ===

def mostrar_resultados(df: pd.DataFrame, gdf: gpd.GeoDataFrame, department_name: str, epicentro_name: str):
    """
    Funci√≥n principal: Prepara los datos, crea el grafo, consolida y muestra el reporte final.
    """
    
    DEPARTAMENTO_ANALISIS = department_name
    EPICENTRO_INICIAL = epicentro_name
    global CRIME_FOCUS_TYPES
    
    # 1. PREPARACI√ìN Y FILTRADO DE DATOS (LA NUEVA L√ìGICA)
    print(f"\n[INFO] 1/4. Filtrando y preparando datos para {DEPARTAMENTO_ANALISIS}...")
    df_filtrado, gdf_filtrado = _preparar_datos_filtrados(df, gdf, DEPARTAMENTO_ANALISIS)
    
    if df_filtrado.empty or gdf_filtrado.empty:
        print("Error: Los datos filtrados est√°n vac√≠os. No se puede proceder.")
        return

    # 2. Creaci√≥n del Grafo Global
    print(f"\n[INFO] 2/4. Creando estructura de an√°lisis (Grafo) con datos preparados...")
    
    # NOTA: Ahora _create_graph_from_data recibe datos YA FILTRADOS Y NORMALIZADOS.
    # Esto soluciona el problema de los ceros sin tocar B_algoritmos.
    G_GLOBAL = _create_graph_from_data(
        df_filtrado, # Pasa el DF de delitos filtrado y normalizado
        gdf_filtrado, # Pasa el GDF filtrado y normalizado
        department=DEPARTAMENTO_ANALISIS,
        crime_types=CRIME_FOCUS_TYPES 
    )
    
    if G_GLOBAL is None or G_GLOBAL.number_of_nodes() == 0:
        print(f"Error fatal: El grafo no tiene nodos. Revise B_algoritmos.py (funci√≥n _create_graph_from_data) si persiste.")
        return
        
    # 3. Diagn√≥stico de Datos (Verificaci√≥n de casos > 0)
    
    print("--- üî¨ DIAGN√ìSTICO DE CARGA DE DATOS ---")
    total_focus_cases_sum = 0
    num_diagnosed = 0
    for node in G_GLOBAL.nodes:
        if num_diagnosed >= 3: break
        case_data = G_GLOBAL.nodes[node].get('cases_by_type', {})
        total_focus_cases = sum(case_data.get(c, 0) for c in CRIME_FOCUS_TYPES)
        total_focus_cases_sum += total_focus_cases
        num_diagnosed += 1
        
    if total_focus_cases_sum == 0 and G_GLOBAL.number_of_nodes() > 0:
        print("üõë ALERTA CR√çTICA: La suma de casos focales en los nodos de muestra es CERO.")
        print("üõë **Acci√≥n:** Revise la funci√≥n _create_graph_from_data: no est√° mapeando los casos del DataFrame filtrado.")
    else:
        print(f"‚úÖ Integridad de datos OK. {G_GLOBAL.number_of_nodes()} distritos cargados y con casos.")
        
    print("---------------------------------------")
    
    # 4. Consolidaci√≥n de Resultados e Impresi√≥n
    print("[INFO] 3/4. Ejecutando an√°lisis algor√≠tmicos y consolidando resultados...")
    reporte_final_data = consolidar_resultados(
        G_base=G_GLOBAL, 
        department=DEPARTAMENTO_ANALISIS, 
        epicentro=EPICENTRO_INICIAL 
    )

    print("[INFO] 4/4. Generando reporte escrito final.")
    imprimir_reporte_final(reporte_final_data)