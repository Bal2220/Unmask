# modulos/B_resultados.py

# modulos/B_resultados.py

import pandas as pd
import numpy as np
import networkx as nx
import geopandas as gpd
from typing import List, Dict, Tuple, Optional

from modulos.B_algoritmos import _filter_subgraph, _get_case_count, _create_graph_from_data, expansion_tree, floyd_warshall_routes, kruskal_mst_analysis

# --- Subtipos de Delito Focales para el Reporte EstratÃ©gico ---
CRIME_FOCUS_TYPES = ['EXTORSIÃ“N', 'HOMICIDIOS', 'SICARIATO']


def _sigla_distrito(nombre: str) -> str:
    tokens = [t for t in nombre.split() if t]
    if not tokens:
        return (nombre[:3] or "ND").upper()
    if len(tokens) == 1:
        return tokens[0][:3].upper()
    return "".join(token[0] for token in tokens[:3]).upper()


def _formatear_numero(valor: float) -> str:
    try:
        if isinstance(valor, (int, float)):
            return f"{valor:,}".replace(",", ".")
    except Exception:
        pass
    return str(valor)


def _preparar_datos_filtrados(df_delitos: pd.DataFrame, gdf_geo: gpd.GeoDataFrame, department: str) -> Tuple[pd.DataFrame, gpd.GeoDataFrame]:
    """
    Realiza el filtrado y normalizaciÃ³n de DataFrames para asegurar la coincidencia de nombres
    antes de pasarlos a la funciÃ³n _create_graph_from_data.
    
    Esta funciÃ³n SOLUCIONA el problema de los 'ceros' al estandarizar los nombres de distritos.
    """
    # NormalizaciÃ³n del departamento
    dept_norm = department.upper().strip()

    # 1. Filtrar GeoDataFrame por el departamento
    # Suponemos que la columna de departamento en el GDF es 'NOMBDEP'
    gdf_dep = gdf_geo[gdf_geo["NOMBDEP"].str.upper().str.strip() == dept_norm].copy()
    
    if gdf_dep.empty:
        print(f"Error: No se encontraron datos geogrÃ¡ficos para {department}.")
        return pd.DataFrame(), gpd.GeoDataFrame()

    # ** PASO CRÃTICO: NORMALIZACIÃ“N DE GEOMETRÃA **
    gdf_dep = gdf_dep[gdf_dep.geometry.notna()].copy()

    # 2. Filtrar el DataFrame de Delitos
    # Suponemos que la columna de departamento en el DF es 'DPTO_HECHO_NEW'
    df_dep = df_delitos[df_delitos["DPTO_HECHO_NEW"].str.upper().str.strip() == dept_norm].copy()
    
    if df_dep.empty:
        print(f"Advertencia: El DataFrame de delitos filtrado por departamento estÃ¡ vacÃ­o para {department}.")
        return pd.DataFrame(), gdf_dep
    
    
    # Crea un set de nombres de distritos vÃ¡lidos del GDF
    valid_districts = set(gdf_dep["NOMBDIST"].str.upper().str.strip())
    
    # Normaliza la columna 'DIST_HECHO' en el DF de delitos
    df_dep['DIST_HECHO_NORM'] = df_dep['DIST_HECHO'].str.upper().str.strip()
    
    # Filtra el DF de delitos para solo incluir distritos que existen en el GDF
    df_dep = df_dep[df_dep['DIST_HECHO_NORM'].isin(valid_districts)].copy()
    
    print(f"[INFO] PreparaciÃ³n de datos: {len(df_dep)} casos de delitos y {len(gdf_dep)} distritos listos.")
    
    return df_dep, gdf_dep


# === 1. FUNCIÃ“N DE CÃLCULO Y CONSOLIDACIÃ“N: consolidar_resultados ===


def consolidar_resultados(G_base: nx.Graph, department: str, epicentro: str) -> Dict:
    """
    Ejecuta todos los anÃ¡lisis de grafos y consolida los hallazgos.
    """
    print(f"\n==================== 1/3. INICIANDO CONSOLIDACIÃ“N DE RESULTADOS PARA {department.upper()} ====================")

    # 1. Filtro y VerificaciÃ³n (G_base ya debe ser el grafo del departamento)
    G_filtered = G_base # Asumimos que _create_graph_from_data ya creÃ³ el grafo filtrado
    
    if G_filtered.number_of_nodes() == 0:
        print("Advertencia: El grafo estÃ¡ vacÃ­o. No se puede generar el reporte.")
        return {}

    # 2. EjecuciÃ³n de los Algoritmos de Grafo
    print("[INFO] Ejecutando algoritmos de anÃ¡lisis estructural...")
    # NOTA: Los algoritmos deben poder manejar grafos grandes y filtrar internamente
    bfs_stats = expansion_tree(G_base, epicentro, method='bfs', crime_types=CRIME_FOCUS_TYPES, department=department)
    fw_stats = floyd_warshall_routes(G_base, mode='volume', crime_types=CRIME_FOCUS_TYPES, department=department)
    kruskal_stats = kruskal_mst_analysis(G_base, k=None, crime_types=CRIME_FOCUS_TYPES, department=department)
    
    reporte_final = {}
    
    # --- PARTE 1: MÃ©tricas de Alto Nivel ðŸ“Š ---
    # ... (Se mantiene la lÃ³gica original, usando G_filtered = G_base) ...
    total_casos_focus_subgraph = sum(_get_case_count(G_filtered, n, CRIME_FOCUS_TYPES) for n in G_filtered.nodes())
    total_nodos_subgraph = G_filtered.number_of_nodes()
    
    try:
        all_paths = [p['path'] for p in fw_stats.get('critical_paths', [])]
        node_counts = pd.Series([node for path in all_paths for node in path]).value_counts()
        bridge_threshold = node_counts.quantile(0.75) if not node_counts.empty else 0
        num_distritos_puente = len(node_counts[node_counts >= bridge_threshold])
        bridge_nodes_list = list(node_counts[node_counts >= bridge_threshold].index)
    except:
        num_distritos_puente = 0
        bridge_nodes_list = []

    mst_stats = kruskal_stats.get('stats', {}) if isinstance(kruskal_stats, dict) else {}

    metrica_global = {
        'total_distritos_analizados': total_nodos_subgraph,
        'total_casos_focus_subtipos': total_casos_focus_subgraph,
        'total_epicentro_detectados': 1, 
        'total_rutas_criticas_fw': fw_stats.get('stats', {}).get('num_caminos_calculados', 0) if isinstance(fw_stats, dict) else fw_stats.get('num_caminos_calculados', 0),
        'total_distritos_puente': num_distritos_puente,
        'total_conexiones_mst': mst_stats.get('MST_aristas', 0),
        'total_casos_ruta_max_conc': fw_stats.get('stats', {}).get('mayor_concentracion_casos', 0) if isinstance(fw_stats, dict) else fw_stats.get('mayor_concentracion_casos', 0),
        'peso_total_mst_inverso': mst_stats.get('peso_total_MST', 0),
    }
    reporte_final['MÃ©tricas Globales'] = metrica_global
    
    # --- PARTE 2: Nodos EstratÃ©gicos Identificados (Distritos) ðŸš¨ ---
    print("\n--- 2. IDENTIFICANDO NODOS ESTRATÃ‰GICOS ---")
    
    # ... (Se mantiene la lÃ³gica original de clasificaciÃ³n y reporte) ...
    nodos_reporte = []
    cases_list = [_get_case_count(G_filtered, n, CRIME_FOCUS_TYPES) for n in G_filtered.nodes()]
    threshold_alta = np.percentile(cases_list, 75) if cases_list else 0
    
    for node in G_filtered.nodes():
        cases_total_focus = _get_case_count(G_filtered, node, CRIME_FOCUS_TYPES)
        cases_by_type = G_filtered.nodes[node].get('cases_by_type', {})
        extorsion_count = cases_by_type.get('EXTORSIÃ“N', 0)
        homicidio_sicariato_count = cases_by_type.get('HOMICIDIOS', 0) + cases_by_type.get('SICARIATO', 0) 

        recomendacion = ""
        is_epicentro = (node == epicentro)
        is_bridge = node in bridge_nodes_list

        if cases_total_focus > threshold_alta and (extorsion_count > 0 or homicidio_sicariato_count > 0):
            recomendacion += "Requiere **IntervenciÃ³n Inmediata (Foco Rojo)**. "
        elif is_bridge and G_filtered.degree(node) >= 3:
            recomendacion += "Es un **Distrito Puente EstratÃ©gico**, su control afecta a mÃºltiples zonas. "
        elif is_epicentro:
            recomendacion += "**Epicentro/Origen** de la expansiÃ³n delictiva. "
        elif cases_total_focus > np.percentile(cases_list, 50):
            recomendacion += "Zona de **Riesgo Alto**, concentraciÃ³n significativa de los subtipos focales. "
        else:
            recomendacion += "Zona de Riesgo Moderado. "
            
        nodos_reporte.append({
            'Distrito': node,
            'Casos (Focus)': cases_total_focus,
            'ExtorsiÃ³n': extorsion_count,
            'Homicidio/Sicariato': homicidio_sicariato_count,
            'Grado': G_filtered.degree(node),
            'RecomendaciÃ³n EstratÃ©gica': recomendacion.strip()
        })
        
    df_nodos_reporte = pd.DataFrame(nodos_reporte).sort_values(by='Casos (Focus)', ascending=False)
    reporte_final['Nodos EstratÃ©gicos'] = df_nodos_reporte.to_dict('records')


    # --- PARTE 3: Rutas CrÃ­ticas de PropagaciÃ³n (Floydâ€“Warshall) ðŸ—ºï¸ ---
    print("\n--- 3. IDENTIFICANDO RUTAS CRÃTICAS ---")

    # ... (Se mantiene la lÃ³gica original) ...
    critical_paths = fw_stats.get('critical_paths', [])
    rutas_reporte = []
    max_concentration = metrica_global['total_casos_ruta_max_conc']
    
    for i, ruta in enumerate(critical_paths[:10]): 
        if max_concentration > 0:
            pct = ruta['concentration'] / max_concentration
            riesgo = "CRÃTICO (MÃ¡xima ConcentraciÃ³n)" if pct >= 0.9 else ("ALTO" if pct >= 0.7 else ("MEDIO" if pct >= 0.5 else "BAJO"))
        else:
            riesgo = "BAJO (ConcentraciÃ³n Nula)"

        rutas_reporte.append({
            'Ruta ID': i + 1,
            'Casos Acumulados (Focus)': ruta['concentration'],
            'Distritos (Corredor)': " -> ".join(ruta['path']),
            'Riesgo': riesgo,
            'Peso Distancia (Inverso)': f"{ruta['cost']:.4f}",
        })

    reporte_final['Rutas CrÃ­ticas FW'] = rutas_reporte

    # --- PARTE 4: Red MÃ­nima de IntervenciÃ³n (Kruskal MST) ðŸ”— ---
    print("\n--- 4. ANALIZANDO RED MÃNIMA DE INTERVENCIÃ“N ---")
    
    # ... (Se mantiene la lÃ³gica original) ...
    mst_metrica = {
        'MST_nodos': mst_stats.get('MST_nodos', 0),
        'MST_aristas': mst_stats.get('MST_aristas', 0),
        'aristas_eliminadas': mst_stats.get('aristas_eliminadas', 0),
        'peso_total_MST_inverso': f"{mst_stats.get('peso_total_MST', 0):.4f}",
        'reduccion_complejidad_pct': mst_stats.get('reduccion_peso_pct', 0),
        'cobertura_territorial': mst_stats.get('cobertura_territorial', "0.00%"),
        'eficiencia_complejidad': f"Se mantiene el {mst_stats.get('cobertura_territorial', '0.00%')} del territorio con una reducciÃ³n de {mst_stats.get('reduccion_peso_pct', 0):.2f}% en la complejidad de la red."
    }
    reporte_final['MÃ©tricas MST'] = mst_metrica
    
    conexiones_reporte = []
    central_column_rank = kruskal_stats.get('central_column', [])
    
    for enlace in central_column_rank:
        if isinstance(enlace, dict):
            conexiones_reporte.append({
                'ConexiÃ³n (Distritos)': enlace.get('Enlace', '--'),
                'Casos Acumulados (Focus)': enlace.get('Casos Acumulados', '--'),
                'Costo (Peso Inverso)': enlace.get('Costo (MST)', '--'),
                'RecomendaciÃ³n': enlace.get('RecomendaciÃ³n', "Enlace de MÃ­nima ConexiÃ³n, crucial para la intervenciÃ³n centralizada."),
            })
        
    reporte_final['Conexiones CrÃ­ticas MST'] = conexiones_reporte

    print("\n==================== 2/3. CONSOLIDACIÃ“N COMPLETADA ====================")
    return reporte_final


# === 2. FUNCIÃ“N DE IMPRESIÃ“N: imprimir_reporte_final (Sin cambios) ===

def imprimir_reporte_final(reporte: Dict):
    """Formatea e imprime el reporte consolidado en la consola (solo texto)."""
    
    if not reporte or 'MÃ©tricas Globales' not in reporte:
        print("\nEl reporte estÃ¡ vacÃ­o o incompleto. No se puede imprimir.")
        return
        
    print("\n\n" + "="*80)
    print("                 ðŸ† INFORME ESTRATÃ‰GICO CONSOLIDADO DE DELITOS ðŸ†")
    print(f" (Foco: {', '.join(CRIME_FOCUS_TYPES)})")
    print("="*80)

    # --- PARTE 1: MÃ©tricas de Alto Nivel ---
    print("\n## 1. MÃ©tricas Clave de Vulnerabilidad Territorial ðŸ“ˆ")
    print("---")
    mg = reporte['MÃ©tricas Globales']
    
    print(f"Total Distritos Analizados:** {mg['total_distritos_analizados']}")
    print(f"Casos Focales Totales (Focus Subtipos):** {mg['total_casos_focus_subtipos']}")
    print(f"Total Epicentros Detectados:** {mg['total_epicentro_detectados']}")
    print(f"Total Rutas CrÃ­ticas FW:** {mg['total_rutas_criticas_fw']}")
    print(f"Total Distritos Puente (EstratÃ©gicos):** {mg['total_distritos_puente']}")
    print(f"Total Conexiones Esenciales MST:** {mg['total_conexiones_mst']}")
    print(f"Casos en Ruta MÃ¡x. ConcentraciÃ³n:** {mg['total_casos_ruta_max_conc']}")
    
    # --- PARTE 2: Nodos EstratÃ©gicos Identificados ---
    print("\n## 2. Nodos EstratÃ©gicos (Distritos) y Riesgo EspecÃ­fico ðŸš¨")
    print("---")
    
    df_nodos = pd.DataFrame(reporte['Nodos EstratÃ©gicos'])
    
    print(df_nodos[['Distrito', 'Casos (Focus)', 'ExtorsiÃ³n', 'Homicidio/Sicariato', 'Grado', 'RecomendaciÃ³n EstratÃ©gica']].to_markdown(index=False, floatfmt=".0f"))
    print("\n**Nota:** Casos (Focus) = Suma de ExtorsiÃ³n, Homicidio y Sicariato.")
    
    print("\n## 3. Corredores Delictivos (Rutas CrÃ­ticas FW) ðŸ—ºï¸")
    print("---")

    # 1. Crea el DataFrame. (AsegÃºrate de que esta lÃ­nea y las siguientes estÃ¡n INDENTADAS)
    df_rutas = pd.DataFrame(reporte['Rutas CrÃ­ticas FW']) 

    # 2. Bloque try-except para manejar el error de columna.
    try:
        # ... (Todo el cÃ³digo de impresiÃ³n de rutas DEBE ESTAR INDENTADO aquÃ­) ...
        if df_rutas.empty:
            print("No se generaron rutas crÃ­ticas de Floyd-Warshall.")
        else:
            print("**Top Rutas con Mayor ConcentraciÃ³n de Casos Focales**")
            
            # Esta lÃ­nea DEBE ESTAR INDENTADA.
            rutas_criticas_altas = df_rutas[df_rutas['Riesgo'].isin(['CRÃTICO (MÃ¡xima ConcentraciÃ³n)', 'ALTO'])]
            
            if not rutas_criticas_altas.empty:
                print(rutas_criticas_altas.to_markdown(index=False))
            else:
                print("No se identificaron rutas CRÃTICAS o ALTAS con la concentraciÃ³n actual de casos.")

    except KeyError:
        print("No se generaron rutas crÃ­ticas de Floyd-Warshall o el cÃ¡lculo de Riesgo fallÃ³.")

    # --- PARTE 4: Red MÃ­nima de IntervenciÃ³n (MST) ---
    print("\n## 4. Red MÃ­nima Esencial de IntervenciÃ³n (Kruskal MST) ðŸ”—")
    print("---")
    
    mm = reporte['MÃ©tricas MST']
    print(f"* **Cobertura Territorial:** {mm['cobertura_territorial']}")
    print(f"* **Eficiencia y Complejidad Reducida:** {mm['eficiencia_complejidad']}")
    print(f"* **Aristas No Esenciales Eliminadas (Complejidad Reducida):** {mm['aristas_eliminadas']}")
    print(f"* **Peso Total Inverso del MST (Costo):** {mm['peso_total_MST_inverso']}")
    
    print("\n### Conexiones CrÃ­ticas del MST (Enlaces mÃ¡s esenciales y de mayor riesgo)")
    df_conexiones = pd.DataFrame(reporte['Conexiones CrÃ­ticas MST'])
    print(df_conexiones.to_markdown(index=False, floatfmt=".4f"))
    
    print("\n" + "="*80)
    print("FIN DEL INFORME ESTRATÃ‰GICO")
    print("="*80)

# === 3. FUNCIÃ“N PRINCIPAL: mostrar_resultados (Nueva LÃ³gica de Filtrado) ===

def mostrar_resultados(df: pd.DataFrame, gdf: gpd.GeoDataFrame, department_name: str, epicentro_name: str):
    """
    FunciÃ³n principal: Prepara los datos, crea el grafo, consolida y muestra el reporte final.
    """
    
    DEPARTAMENTO_ANALISIS = department_name
    EPICENTRO_INICIAL = epicentro_name
    global CRIME_FOCUS_TYPES
    
    # 1. PREPARACIÃ“N Y FILTRADO DE DATOS (LA NUEVA LÃ“GICA)
    print(f"\n[INFO] 1/4. Filtrando y preparando datos para {DEPARTAMENTO_ANALISIS}...")
    df_filtrado, gdf_filtrado = _preparar_datos_filtrados(df, gdf, DEPARTAMENTO_ANALISIS)
    
    if df_filtrado.empty or gdf_filtrado.empty:
        print("Error: Los datos filtrados estÃ¡n vacÃ­os. No se puede proceder.")
        return

    # 2. CreaciÃ³n del Grafo Global
    print(f"\n[INFO] 2/4. Creando estructura de anÃ¡lisis (Grafo) con datos preparados...")
    
    # NOTA: Ahora _create_graph_from_data recibe datos YA FILTRADOS Y NORMALIZADOS.
    # Esto soluciona el problema de los ceros sin tocar B_algoritmos.
    G_GLOBAL = _create_graph_from_data(
        df_filtrado, # Pasa el DF de delitos filtrado y normalizado
        gdf_filtrado, # Pasa el GDF filtrado y normalizado
        department=DEPARTAMENTO_ANALISIS,
        crime_types=CRIME_FOCUS_TYPES 
    )
    
    if G_GLOBAL is None or G_GLOBAL.number_of_nodes() == 0:
        print(f"Error fatal: El grafo no tiene nodos. Revise B_algoritmos.py (funciÃ³n _create_graph_from_data) si persiste.")
        return
        
    # 3. DiagnÃ³stico de Datos (VerificaciÃ³n de casos > 0)
    
    print("--- ðŸ”¬ DIAGNÃ“STICO DE CARGA DE DATOS ---")
    total_focus_cases_sum = 0
    num_diagnosed = 0
    for node in G_GLOBAL.nodes:
        if num_diagnosed >= 3: break
        case_data = G_GLOBAL.nodes[node].get('cases_by_type', {})
        total_focus_cases = sum(case_data.get(c, 0) for c in CRIME_FOCUS_TYPES)
        total_focus_cases_sum += total_focus_cases
        num_diagnosed += 1
        
    if total_focus_cases_sum == 0 and G_GLOBAL.number_of_nodes() > 0:
        print("ðŸ›‘ ALERTA CRÃTICA: La suma de casos focales en los nodos de muestra es CERO.")
        print("ðŸ›‘ **AcciÃ³n:** Revise la funciÃ³n _create_graph_from_data: no estÃ¡ mapeando los casos del DataFrame filtrado.")
    else:
        print(f"âœ… Integridad de datos OK. {G_GLOBAL.number_of_nodes()} distritos cargados y con casos.")
        
    print("---------------------------------------")
    
    # 4. ConsolidaciÃ³n de Resultados e ImpresiÃ³n
    print("[INFO] 3/4. Ejecutando anÃ¡lisis algorÃ­tmicos y consolidando resultados...")
    reporte_final_data = consolidar_resultados(
        G_base=G_GLOBAL, 
        department=DEPARTAMENTO_ANALISIS, 
        epicentro=EPICENTRO_INICIAL 
    )

    print("[INFO] 4/4. Generando reporte escrito final.")
    imprimir_reporte_final(reporte_final_data)


def generar_resumen_ui(
    df: pd.DataFrame,
    gdf: gpd.GeoDataFrame,
    department: str,
    crime_filter: Optional[str] = "TODO",
):
    """Construye un resumen estructurado para la vista grÃ¡fica de Resultados."""

    from modulos import B_algoritmos  # importaciÃ³n diferida para evitar ciclos

    G, crime_types = B_algoritmos.preparar_grafo_para_algoritmos(
        df,
        gdf,
        department,
        crime_filter,
        verbose=False,
    )

    if not G or not G.nodes:
        raise ValueError("No se pudo construir el grafo para los filtros seleccionados.")

    # Epicentro = distrito con mayor acumulado
    epicentro = max(
        G.nodes,
        key=lambda n: _get_case_count(G, n, crime_types),
    )

    bfs = B_algoritmos.expansion_tree(
        G,
        epicentro,
        method="bfs",
        crime_types=crime_types,
        department=department,
        show_plot=False,
        verbose=False,
    )
    fw = B_algoritmos.floyd_warshall_routes(
        G,
        crime_types=crime_types,
        mode="volume",
        department=department,
        show_plot=False,
        verbose=False,
    )
    kruskal = B_algoritmos.kruskal_mst_analysis(
        G,
        k=None,
        crime_types=crime_types,
        department=department,
        show_plot=False,
        verbose=False,
    )

    fw_paths = fw.get("critical_paths", []) if fw else []
    fw_stats = fw.get("stats", {}) if fw else {}
    bridge_nodes = set(fw.get("bridge_nodes", [])) if fw else set()

    mst_stats = kruskal.get("stats", {}) if kruskal else {}
    mst_connections = kruskal.get("central_column", []) if kruskal else []
    mst_image = kruskal.get("image_path") if kruskal else None

    # --- Tarjetas resumen ---
    total_epicentros = max(1, len(bfs.get("clusters", [])) if bfs else 1)
    total_rutas = len(fw_paths)
    total_puentes = len(bridge_nodes)
    total_conexiones_mst = mst_stats.get("MST_aristas", 0)
    casos_rutas = sum(ruta.get("concentration", 0) for ruta in fw_paths[:3])

    cards = [
        {"label": "Epicentros detectados", "value": total_epicentros},
        {"label": "Rutas crÃ­ticas", "value": total_rutas},
        {"label": "Distritos puente", "value": total_puentes},
        {"label": "Conexiones MST", "value": total_conexiones_mst},
        {"label": "Casos en rutas crÃ­ticas", "value": casos_rutas},
    ]

    # --- Nodos estratÃ©gicos ---
    cases_list = [_get_case_count(G, n, crime_types) for n in G.nodes]
    p75 = np.percentile(cases_list, 75) if cases_list else 0
    p55 = np.percentile(cases_list, 55) if cases_list else 0
    bfs_nodes = {n for level in bfs.get("levels", []) for n in level.get("nodes", [])} if bfs else set()
    fw_nodes = {n for ruta in fw_paths for n in ruta.get("path", [])}
    mst_nodes = {item.get("distrito") for item in kruskal.get("critical_nodes", [])} if kruskal else set()

    nodos = []
    for node in sorted(G.nodes, key=lambda n: _get_case_count(G, n, crime_types), reverse=True):
        cases = _get_case_count(G, node, crime_types)
        info = G.nodes[node]
        casos_tipo = info.get("cases_by_type", {})
        extorsion = casos_tipo.get("EXTORSIÃ“N", casos_tipo.get("EXTORSION", 0))
        sicariato = casos_tipo.get("SICARIATO", 0) + casos_tipo.get("HOMICIDIOS", 0)

        nivel = "CrÃ­tico" if cases >= p75 else ("Alto" if cases >= p55 else "Medio")
        rol = "Epicentro principal" if node == epicentro else (
            "Nodo puente estratÃ©gico" if node in bridge_nodes else "Distrito de trÃ¡nsito"
        )

        algoritmos = []
        if node in bfs_nodes or node == epicentro:
            algoritmos.append("BFS")
        if node in fw_nodes:
            algoritmos.append("Floyd")
        if node in mst_nodes:
            algoritmos.append("Kruskal")

        recomendacion = []
        if node == epicentro:
            recomendacion.append("Requiere intervenciÃ³n inmediata. Mayor concentraciÃ³n registrada.")
        if node in bridge_nodes:
            recomendacion.append("Distrito puente que conecta mÃºltiples corredores.")
        if node in mst_nodes:
            recomendacion.append("Clave en la red mÃ­nima; mantener vigilancia.")
        if not recomendacion:
            recomendacion.append("Zona monitoreada. Refuerza patrullaje preventivo.")

        nodos.append({
            "nombre": node,
            "sigla": _sigla_distrito(node),
            "rol": rol,
            "nivel": nivel,
            "extorsion": extorsion,
            "sicariato": sicariato,
            "total": cases,
            "algoritmos": algoritmos,
            "recomendacion": " ".join(recomendacion),
        })

    nodos = nodos[:5]

    # --- Rutas crÃ­ticas ---
    rutas = []
    for idx, ruta in enumerate(fw_paths[:3], start=1):
        path = ruta.get("path", [])
        riesgo = "Riesgo crÃ­tico" if idx == 1 else ("Riesgo alto" if idx == 2 else "Riesgo medio")
        estrategia = "Establecer intervenciÃ³n en puntos intermedios." if idx == 1 else (
            "Operativo conjunto en distritos del corredor." if idx == 2 else "Monitoreo reforzado de accesos."
        )
        rutas.append({
            "id": f"R{idx}",
            "descripcion": "Corredor delictivo prioritario" if idx == 1 else "Corredor supervisado",
            "path": " -> ".join(path),
            "casos": ruta.get("concentration", 0),
            "distancia": max(1, len(path) - 1),
            "riesgo": riesgo,
            "estrategia": estrategia,
        })

    # --- SecciÃ³n MST ---
    mst_metrics = [
        {"label": "Nodos", "value": mst_stats.get("MST_nodos", "--")},
        {"label": "Aristas MST", "value": mst_stats.get("MST_aristas", "--")},
        {"label": "Peso total", "value": int(round(mst_stats.get("peso_total_MST", 0)))},
        {"label": "ReducciÃ³n", "value": f"{mst_stats.get('reduccion_peso_pct', 0):.0f}%"},
    ]

    conexiones_rank = []
    for idx, item in enumerate(mst_connections, start=1):
        conexiones_rank.append({
            "rank": idx,
            "enlace": item.get("Enlace", "--"),
            "casos": item.get("Casos Acumulados", "--"),
        })

    insights = [
        {"label": "Cobertura territorial", "value": mst_stats.get("cobertura_territorial", "--")},
        {"label": "Eficiencia", "value": "Alta" if mst_stats.get("reduccion_peso_pct", 0) >= 10 else "Media"},
        {"label": "Complejidad reducida", "value": f"{mst_stats.get('reduccion_peso_pct', 0):.2f}%"},
    ]

    mst_section = {
        "image_path": mst_image,
        "metrics": mst_metrics,
        "conexiones": conexiones_rank,
        "insights": insights,
    }

    return {
        "department": department,
        "crime_types": crime_types,
        "epicentro": epicentro,
        "cards": cards,
        "nodos": nodos,
        "rutas": rutas,
        "mst": mst_section,
    }